import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler

class RBMLayer:
    def __init__(self, n_visible, n_hidden, learning_rate=0.01, momentum=0.5, weight_decay=0.0001):
        self.n_visible = n_visible
        self.n_hidden = n_hidden
        self.learning_rate = learning_rate
        self.momentum = momentum
        self.weight_decay = weight_decay
        
        self.weights = np.random.normal(0, 0.1, (n_visible, n_hidden))
        self.visible_bias = np.zeros(n_visible)
        self.hidden_bias = np.zeros(n_hidden)
        
        self.weight_update = np.zeros((n_visible, n_hidden))
        self.visible_bias_update = np.zeros(n_visible)
        self.hidden_bias_update = np.zeros(n_hidden)
    
    def sigmoid(self, x):
        return 1.0 / (1.0 + np.exp(-x))
    
    def sample_hidden(self, visible_states):
        hidden_activations = np.dot(visible_states, self.weights) + self.hidden_bias
        hidden_probs = self.sigmoid(hidden_activations)
        hidden_states = (hidden_probs > np.random.random(hidden_probs.shape)).astype(float)
        return hidden_probs, hidden_states
    
    def sample_visible(self, hidden_states):
        visible_activations = np.dot(hidden_states, self.weights.T) + self.visible_bias
        visible_probs = self.sigmoid(visible_activations)
        visible_states = (visible_probs > np.random.random(visible_probs.shape)).astype(float)
        return visible_probs, visible_states
    
    def contrastive_divergence(self, visible_data, k=1):
        positive_hidden_probs, positive_hidden_states = self.sample_hidden(visible_data)
        positive_associations = np.dot(visible_data.T, positive_hidden_probs)
        
        hidden_states = positive_hidden_states
        for i in range(k):
            visible_probs, visible_states = self.sample_visible(hidden_states)
            hidden_probs, hidden_states = self.sample_hidden(visible_states)
        
        negative_associations = np.dot(visible_probs.T, hidden_probs)
        
        batch_size = visible_data.shape[0]
        
        weight_gradient = (positive_associations - negative_associations) / batch_size - self.weight_decay * self.weights
        visible_bias_gradient = np.mean(visible_data - visible_probs, axis=0)
        hidden_bias_gradient = np.mean(positive_hidden_probs - hidden_probs, axis=0)
        
        self.weight_update = self.momentum * self.weight_update + self.learning_rate * weight_gradient
        self.visible_bias_update = self.momentum * self.visible_bias_update + self.learning_rate * visible_bias_gradient
        self.hidden_bias_update = self.momentum * self.hidden_bias_update + self.learning_rate * hidden_bias_gradient
        
        self.weights += self.weight_update
        self.visible_bias += self.visible_bias_update
        self.hidden_bias += self.hidden_bias_update
        
        return positive_hidden_probs
    
    def reconstruct(self, visible_data):
        hidden_probs, _ = self.sample_hidden(visible_data)
        visible_probs, _ = self.sample_visible(hidden_probs)
        return visible_probs
    
    def get_hidden_outputs(self, visible_data):
        hidden_probs, _ = self.sample_hidden(visible_data)
        return hidden_probs
    
    def get_reconstruction_error(self, visible_data):
        reconstructed = self.reconstruct(visible_data)
        return np.mean((visible_data - reconstructed) ** 2)
    
    def fit(self, data, epochs=10, batch_size=10, k=1):
        n_samples = data.shape[0]
        reconstruction_errors = []
        
        for epoch in range(epochs):
            indices = np.random.permutation(n_samples)
            data_shuffled = data[indices]
            
            total_error = 0
            n_batches = n_samples // batch_size
            
            for i in range(n_batches):
                batch = data_shuffled[i * batch_size:(i + 1) * batch_size]
                self.contrastive_divergence(batch, k)
                total_error += self.get_reconstruction_error(batch)
            
            avg_error = total_error / n_batches
            reconstruction_errors.append(avg_error)
            print(f"Layer {self.n_visible}â†’{self.n_hidden} - Epoch {epoch+1}/{epochs} - Error: {avg_error:.4f}")
        
        return reconstruction_errors


class StackedRBM:
    def __init__(self, layer_sizes, learning_rate=0.01, momentum=0.5, weight_decay=0.0001):
        if len(layer_sizes) < 2:
            raise ValueError("At least two layer sizes must be provided (input and one hidden layer)")
        
        self.layer_sizes = layer_sizes
        self.n_layers = len(layer_sizes) - 1
        self.layers = []
        
        for i in range(self.n_layers):
            self.layers.append(RBMLayer(
                n_visible=layer_sizes[i],
                n_hidden=layer_sizes[i+1],
                learning_rate=learning_rate,
                momentum=momentum,
                weight_decay=weight_decay
            ))
        
        self.image_height = None
        self.image_width = None
        self.channels = None
    
    def preprocess_images(self, images):
        if len(images.shape) == 4:  # Batch of color images [batch_size, height, width, channels]
            self.image_height, self.image_width, self.channels = images.shape[1:]
            flattened = images.reshape(images.shape[0], -1)
        elif len(images.shape) == 3:  # Batch of grayscale images [batch_size, height, width]
            self.image_height, self.image_width = images.shape[1:]
            self.channels = 1
            flattened = images.reshape(images.shape[0], -1)
        else:
            raise ValueError("Images must be 3D (batch of grayscale) or 4D (batch of color images)")
        
        scaler = MinMaxScaler(feature_range=(0, 1))
        return scaler.fit_transform(flattened)
    
    def reshape_to_images(self, flattened_data):
        if self.channels == 1:
            return flattened_data.reshape(-1, self.image_height, self.image_width)
        else:
            return flattened_data.reshape(-1, self.image_height, self.image_width, self.channels)
    
    def pretrain(self, images, epochs_per_layer=10, batch_size=10, k=1, visualize_progress=False):
        processed_data = self.preprocess_images(images)
        layer_inputs = processed_data
        all_errors = []
        
        for i, layer in enumerate(self.layers):
            print(f"\nPretraining layer {i+1}/{self.n_layers}")
            errors = layer.fit(layer_inputs, epochs=epochs_per_layer, batch_size=batch_size, k=k)
            all_errors.append(errors)
            
            if i < self.n_layers - 1:
                layer_inputs = layer.get_hidden_outputs(layer_inputs)
                
            if visualize_progress and i == 0:
                self.visualize_first_layer_reconstruction(processed_data[:5])
        
        return all_errors
    
    def up_propagate(self, data):
        activations = data
        for layer in self.layers:
            activations = layer.get_hidden_outputs(activations)
        return activations
    
    def down_propagate(self, hidden_activations):
        activations = hidden_activations
        for layer in reversed(self.layers):
            activations, _ = layer.sample_visible(activations)
        return activations
    
    def reconstruct(self, data):
        hidden_activations = self.up_propagate(data)
        return self.down_propagate(hidden_activations)
    
    def get_reconstruction_error(self, data):
        reconstructed = self.reconstruct(data)
        return np.mean((data - reconstructed) ** 2)
    
    def visualize_first_layer_reconstruction(self, original_data, n_samples=5):
        if n_samples > original_data.shape[0]:
            n_samples = original_data.shape[0]
        
        samples = original_data[:n_samples]
        
        reconstructed = self.layers[0].reconstruct(samples)
        
        samples_imgs = self.reshape_to_images(samples)
        reconstructed_imgs = self.reshape_to_images(reconstructed)
        
        plt.figure(figsize=(n_samples * 4, 8))
        
        for i in range(n_samples):
            plt.subplot(2, n_samples, i + 1)
            if self.channels == 1:
                plt.imshow(samples_imgs[i], cmap='gray')
            else:
                plt.imshow(samples_imgs[i])
            plt.title("Original")
            plt.axis('off')
            
            plt.subplot(2, n_samples, i + 1 + n_samples)
            if self.channels == 1:
                plt.imshow(reconstructed_imgs[i], cmap='gray')
            else:
                plt.imshow(reconstructed_imgs[i])
            plt.title("First Layer Reconstruction")
            plt.axis('off')
        
        plt.tight_layout()
        plt.show()
    
    def visualize_full_reconstruction(self, original_data, n_samples=5):
        if n_samples > original_data.shape[0]:
            n_samples = original_data.shape[0]
        
        processed_data = self.preprocess_images(original_data)
        samples = processed_data[:n_samples]
        
        reconstructed = self.reconstruct(samples)
        
        samples_imgs = self.reshape_to_images(samples)
        reconstructed_imgs = self.reshape_to_images(reconstructed)
        
        plt.figure(figsize=(n_samples * 4, 8))
        
        for i in range(n_samples):
            plt.subplot(2, n_samples, i + 1)
            if self.channels == 1:
                plt.imshow(samples_imgs[i], cmap='gray')
            else:
                plt.imshow(samples_imgs[i])
            plt.title("Original")
            plt.axis('off')
            
            plt.subplot(2, n_samples, i + 1 + n_samples)
            if self.channels == 1:
                plt.imshow(reconstructed_imgs[i], cmap='gray')
            else:
                plt.imshow(reconstructed_imgs[i])
            plt.title("Full Stack Reconstruction")
            plt.axis('off')
        
        plt.tight_layout()
        plt.show()
    
    def visualize_layer_features(self, layer_idx=0, n_features=10):
        if layer_idx >= self.n_layers:
            raise ValueError(f"Invalid layer index. Must be between 0 and {self.n_layers-1}")
        
        layer = self.layers[layer_idx]
        
        if layer_idx == 0:
            if self.channels == 1:
                feature_shape = (self.image_height, self.image_width)
            else:
                feature_shape = (self.image_height, self.image_width, self.channels)
        else:
            # For higher layers, visualize as a 1D histogram or reshape to square for visual convenience
            n_features_sqrt = int(np.sqrt(layer.n_hidden))
            feature_shape = (n_features_sqrt, n_features_sqrt)
        
        n_cols = min(5, n_features)
        n_rows = (n_features + n_cols - 1) // n_cols
        
        plt.figure(figsize=(n_cols * 3, n_rows * 3))
        
        for i in range(min(n_features, layer.n_hidden)):
            plt.subplot(n_rows, n_cols, i + 1)
            
            if layer_idx == 0:
                feature = layer.weights[:, i].reshape(feature_shape)
                if self.channels == 1:
                    plt.imshow(feature, cmap='viridis')
                else:
                    plt.imshow(feature)
            else:
                try:
                    # Try to reshape to 2D for visualization
                    feature = layer.weights[:, i].reshape(feature_shape)
                    plt.imshow(feature, cmap='viridis')
                except:
                    # If reshape fails, display as 1D plot
                    plt.plot(layer.weights[:, i])
                
            plt.title(f"Layer {layer_idx+1} Feature {i+1}")
            plt.axis('off')
            
        plt.tight_layout()
        plt.show()
    
    def extract_features(self, data):
        processed_data = self.preprocess_images(data)
        return self.up_propagate(processed_data)
    
    def save_model(self, filename):
        model_data = {
            'n_layers': self.n_layers,
            'layer_sizes': self.layer_sizes,
            'image_height': self.image_height,
            'image_width': self.image_width,
            'channels': self.channels
        }
        
        for i, layer in enumerate(self.layers):
            model_data[f'layer_{i}_weights'] = layer.weights
            model_data[f'layer_{i}_visible_bias'] = layer.visible_bias
            model_data[f'layer_{i}_hidden_bias'] = layer.hidden_bias
        
        np.savez(filename, **model_data)
        print(f"Model saved to {filename}.npz")
    
    def load_model(self, filename):
        data = np.load(filename + '.npz')
        
        self.n_layers = data['n_layers']
        self.layer_sizes = data['layer_sizes']
        self.image_height = data['image_height']
        self.image_width = data['image_width']
        self.channels = data['channels']
        
        self.layers = []
        for i in range(self.n_layers):
            layer = RBMLayer(
                n_visible=self.layer_sizes[i],
                n_hidden=self.layer_sizes[i+1]
            )
            layer.weights = data[f'layer_{i}_weights']
            layer.visible_bias = data[f'layer_{i}_visible_bias']
            layer.hidden_bias = data[f'layer_{i}_hidden_bias']
            self.layers.append(layer)
        
        print(f"Model loaded from {filename}.npz")


# Example usage with MNIST
if __name__ == "__main__":
    try:
        from sklearn.datasets import fetch_openml
        from sklearn.model_selection import train_test_split
        
        # Load MNIST dataset
        mnist = fetch_openml('mnist_784', version=1, parser='auto')
        X = mnist.data.astype('float32').values
        X = X.reshape(-1, 28, 28)  # Reshape to images
        
        # Take a subset for faster training
        X_subset = X[:2000]
        
        # Create stacked RBM
        layer_sizes = [784, 256, 100, 50]  # Input -> Hidden layers
        stacked_rbm = StackedRBM(layer_sizes, learning_rate=0.01)
        
        # Pretrain the model
        errors = stacked_rbm.pretrain(
            X_subset, 
            epochs_per_layer=10, 
            batch_size=64, 
            k=1, 
            visualize_progress=True
        )
        
        # Visualize features learned by first layer
        stacked_rbm.visualize_layer_features(layer_idx=0, n_features=20)
        
        # Visualize full stack reconstruction
        stacked_rbm.visualize_full_reconstruction(X_subset[:5])
        
        # Save the model
        stacked_rbm.save_model("stacked_rbm_mnist_model")
        
    except ImportError:
        print("Please install scikit-learn to run the example with MNIST data")
        
        # Alternative with random image data
        print("Running with random image data instead")
        random_images = np.random.random((100, 32, 32))
        
        # Create stacked RBM with smaller layers for the example
        layer_sizes = [32*32, 128, 64, 32]
        stacked_rbm = StackedRBM(layer_sizes, learning_rate=0.01)
        
        # Pretrain with random data
        stacked_rbm.pretrain(
            random_images, 
            epochs_per_layer=5, 
            batch_size=10, 
            visualize_progress=True
        )
